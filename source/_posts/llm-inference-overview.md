---
title: llm-inference-overview
date: 2025-06-03 23:13:31
tags:
hide: true
draft: true
---

# 一. 算法创新 (Algorithmic Innovations)
## 1. 解码算法 (Decoding Algorithm)
### 1.1 非自回归解码 (Non-autoregressive Decoding)
### 1.2 投机采样解码 (Speculative Decoding)
### 1.3 提前退出 (Early Exiting)
### 1.4 级联推理 (Cascade Inference)

## 2. 模型结构设计 (Model Architecture Design)
### 2.1 配置缩减 (Config Downsizing)
### 2.2 注意力简化 (Attention Simplification)
### 2.3 循环单元 (Recurrent Unit)
### 2.4 激活共享 (Activation Sharing)
### 2.5 条件计算 (Conditional Computing)
## 3. 模型压缩 (Model Compression)
### 3.1 知识蒸馏 (Knowledge Distillation)
### 3.2 网络剪枝 (Network Pruning)
# 二. 系统优化 (System Optimizations)
## 1. 低比特量化 (Low-bit Quantization)
## 2. 并行计算 (Parallel Computation)
### 2.1 模型并行 (Model Parallelism)
### 2.2 去中心化推理 (Decentralized Inference)
## 3. 内存管理 (Memory Management)
## 4. 请求调度 (Request Scheduling)
## 5. 内核优化 (Kernel Optimizations)
### 5.1 算子融合 (Operator Fusion)
### 5.2 定制注意力 (Tailored Attention)
### 5.3 采样优化 (Sampling Optimization)
### 5.4 可变序列长度 (Variable Sequence Length)
### 5.5 自动编译 (Automatic Compilation)